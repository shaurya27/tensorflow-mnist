{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=mnist.train.images\n",
    "y=mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (x.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None,784])\n",
    "Y_=tf.placeholder(\"float\",[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchnorm(Ylogits,beta,scale):\n",
    "    #exp_moving_avg = tf.train.ExponentialMovingAverage(0.998, iteration)\n",
    "    bnepsilon = 1e-5\n",
    "    mean, variance = tf.nn.moments(Ylogits, [0])\n",
    "    BN = tf.nn.batch_normalization(Ylogits,mean,variance,beta,scale,bnepsilon)\n",
    "    return BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# five layers and their number of neurons (tha last layer has 10 softmax neurons)\n",
    "L = 200\n",
    "M = 100\n",
    "N = 60\n",
    "O = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S1 = tf.Variable(tf.ones([L]))\n",
    "O1 = tf.Variable(tf.zeros([L]))\n",
    "\n",
    "S2 = tf.Variable(tf.ones([M]))\n",
    "O2 = tf.Variable(tf.zeros([M]))\n",
    "\n",
    "S3 = tf.Variable(tf.ones([N]))\n",
    "O3 = tf.Variable(tf.zeros([N]))\n",
    "\n",
    "S4 = tf.Variable(tf.ones([O]))\n",
    "O4 = tf.Variable(tf.zeros([O]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1))  # 784 = 28 * 28\n",
    "#B1 = tf.Variable(tf.zeros([L]))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "#B2 = tf.Variable(tf.zeros([M]))\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([M,N], stddev=0.1))\n",
    "#B3 = tf.Variable(tf.zeros([N]))\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))\n",
    "#B4 = tf.Variable(tf.zeros([O]))\n",
    "\n",
    "W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y1 = (tf.matmul(X, W1))\n",
    "BN1=batchnorm(Y1,O1,S1)\n",
    "l1_BN = tf.nn.sigmoid(BN1)\n",
    "\n",
    "Y2 = (tf.matmul(l1_BN, W2))\n",
    "BN2=batchnorm(Y2,O2,S2)\n",
    "l2_BN = tf.nn.sigmoid(BN2)\n",
    "\n",
    "Y3 = (tf.matmul(l2_BN, W3))\n",
    "BN3=batchnorm(Y3,O3,S3)\n",
    "l3_BN = tf.nn.sigmoid(BN3)\n",
    "\n",
    "Y4 = (tf.matmul(l3_BN, W4))\n",
    "BN4=batchnorm(Y4,O4,S4)\n",
    "l4_BN = tf.nn.sigmoid(BN4)\n",
    "\n",
    "Ylogits_BN = tf.matmul(l4_BN, W5) + B5\n",
    "Ylogits_BN = tf.nn.softmax(Ylogits_BN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits_BN, labels=Y_)\n",
    "cost = tf.reduce_mean(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(Ylogits_BN, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable learning rate\n",
    "lr = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training step, the learning rate is a placeholder\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning rate decay\n",
    "max_learning_rate = 0.003\n",
    "min_learning_rate = 0.0001\n",
    "decay_speed = 2000.0 # 0.003-0.0001-2000=>0.9826 done in 5000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 25\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init =tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epchos 1 cross entropy=1.8001413512229925\n",
      "epchos 2 cross entropy=1.5547489666938787\n",
      "epchos 3 cross entropy=1.512746886990285\n",
      "epchos 4 cross entropy=1.5026151917197483\n",
      "epchos 5 cross entropy=1.4956990708004336\n",
      "epchos 6 cross entropy=1.4928617685491399\n",
      "epchos 7 cross entropy=1.489466449780896\n",
      "epchos 8 cross entropy=1.4858593355525629\n",
      "epchos 9 cross entropy=1.484520356004888\n",
      "epchos 10 cross entropy=1.4823024064844295\n",
      "epchos 11 cross entropy=1.4802128234776564\n",
      "epchos 12 cross entropy=1.4798860296336083\n",
      "epchos 13 cross entropy=1.4797930830175223\n",
      "epchos 14 cross entropy=1.4774635770104143\n",
      "epchos 15 cross entropy=1.477598488981074\n",
      "epchos 16 cross entropy=1.4764033289389193\n",
      "epchos 17 cross entropy=1.4753799590197476\n",
      "epchos 18 cross entropy=1.4757269072532648\n",
      "epchos 19 cross entropy=1.4740860373323612\n",
      "epchos 20 cross entropy=1.4743659455125981\n",
      "epchos 21 cross entropy=1.4745512546192523\n",
      "epchos 22 cross entropy=1.4728264125910673\n",
      "epchos 23 cross entropy=1.4726136827468876\n",
      "epchos 24 cross entropy=1.4722754270380196\n",
      "epchos 25 cross entropy=1.4712658472494649\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        c=0.0\n",
    "        avg_cost=0.0\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            \n",
    "            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-i/decay_speed)\n",
    "            \n",
    "            batch_X, batch_Y = mnist.train.next_batch(batch_size)\n",
    "            #print(batch_X.shape)\n",
    "            _,c=sess.run([optimizer,cost], feed_dict={X:batch_X,Y_:batch_Y,lr: learning_rate})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print(\"epchos {} cross entropy={}\".format(epoch+1,avg_cost))\n",
    "            \n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    #correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print( \"Accuracy:\", accuracy.eval({X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
